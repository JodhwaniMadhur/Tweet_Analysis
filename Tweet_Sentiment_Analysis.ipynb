{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (1.19.2)\n",
      "Requirement already satisfied: sklearn in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: nltk in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (3.6.5)\n",
      "Requirement already satisfied: seaborn in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (0.11.1)\n",
      "Requirement already satisfied: matplotlib in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (3.4.2)\n",
      "Requirement already satisfied: fast_ml in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (3.68)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: click in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from nltk) (2021.10.8)\n",
      "Requirement already satisfied: tqdm in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: joblib in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from seaborn) (1.6.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from matplotlib) (8.3.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: six in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from click->nltk) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.10.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/madhurjodhwani/opt/anaconda3/envs/tf/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy sklearn nltk fast_ml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         target                                               text\n",
      "0             0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1             0  is upset that he can't update his Facebook by ...\n",
      "2             0  @Kenichan I dived many times for the ball. Man...\n",
      "3             0    my whole body feels itchy and like its on fire \n",
      "4             0  @nationwideclass no, it's not behaving at all....\n",
      "...         ...                                                ...\n",
      "1599995       4  Just woke up. Having no school is the best fee...\n",
      "1599996       4  TheWDB.com - Very cool to hear old Walt interv...\n",
      "1599997       4  Are you ready for your MoJo Makeover? Ask me f...\n",
      "1599998       4  Happy 38th Birthday to my boo of alll time!!! ...\n",
      "1599999       4  happy #charitytuesday @theNSPCC @SparksCharity...\n",
      "\n",
      "[1600000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.read_csv('./tweet.csv',names=['target','id','date','flag','user','text'])\n",
    "#print(data.info)\n",
    "#print(data.describe)\n",
    "\n",
    "data.drop(labels='flag',axis=1,inplace=True)\n",
    "data.drop(labels='date',axis=1,inplace=True)\n",
    "data.drop(labels='id',axis=1,inplace=True)\n",
    "data.drop(labels='user',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "def removeUnimportantData(data):\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    stop = stopwords.words('english')\n",
    "    data['text'] = data['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    #data['tweet_without_stopwords']=\n",
    "    return data['text']\n",
    "\n",
    "def removeSpecialChar(data):\n",
    "    data = data.str.replace(r\"[^a-zA-Z]+\", \" \").str.strip()\n",
    "    data = data.str.replace(r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\", \" \").str.strip()\n",
    "    data = data.str.replace('@[^\\s]+', \" \").str.strip()\n",
    "    data = data.str.replace(r\"(.)\\1\\1+\", \" \").str.strip()\n",
    "    #data = data.str.replace(r\"\\1\\1\", \" \").str.strip()\n",
    "    data=data.str.lower()\n",
    "    data = data.str.replace(r'\\b\\w\\b', '').str.replace(r'\\s+', ' ')\n",
    "    return data\n",
    "\n",
    "def getWordCount(data):\n",
    "    count = data.str.split().str.len()\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "#data.insert(3,'Average Length',data['Avg_length'],True)\n",
    "\n",
    "#X_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(data, target = 'target', train_size=0.9, valid_size=0.05, test_size=0.05)\n",
    "\n",
    "#X_train,X_valid,X_test=removeUnimportantData(X_train),removeUnimportantData(X_valid),removeUnimportantData(X_test)\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Number_of_words']=getWordCount(data['text'])\n",
    "data['Avg_length'] = data[\"text\"].apply(lambda x: np.mean([len(w) for w in x.split()]))\n",
    "data['Tweet_Length']=data['text'].str.len()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=removeSpecialChar(removeUnimportantData(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import PorterStemmer\n",
    "ps=nltk.PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "#data['text']=data['text'].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   target           1600000 non-null  int64  \n",
      " 1   text             1600000 non-null  object \n",
      " 2   Number_of_words  1600000 non-null  int64  \n",
      " 3   Avg_length       1600000 non-null  float64\n",
      " 4   Tweet_Length     1600000 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 61.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         target  Number_of_words  Avg_length  Tweet_Length\n",
      "0             0               19    5.052632           115\n",
      "1             0               21    4.285714           111\n",
      "2             0               18    3.944444            89\n",
      "3             0               10    3.700000            47\n",
      "4             0               21    4.285714           111\n",
      "...         ...              ...         ...           ...\n",
      "1599995       4               11    4.090909            56\n",
      "1599996       4               11    5.909091            76\n",
      "1599997       4               11    4.181818            57\n",
      "1599998       4               12    4.416667            65\n",
      "1599999       4                5   11.400000            62\n",
      "\n",
      "[1600000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Validation set is: 0.5813375\n",
      "F1 score of Validation set is: 0.5813375\n",
      "Accuracy on Test set is: 0.5794\n",
      "F1 score of Test set is: 0.5794\n",
      "Accuracy on Validation set is: 0.5814125\n",
      "F1 score of Validation set is: 0.5814125\n",
      "Accuracy on Test set is: 0.579425\n",
      "F1 score of Test set is: 0.579425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "\n",
    "#data.drop(labels='text',inplace=True)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(data, target = 'target', train_size=0.9, valid_size=0.05, test_size=0.05)\n",
    "\n",
    "dtc=DecisionTreeClassifier(random_state=42)\n",
    "dtc.fit(X_train,y_train)\n",
    "y_val_predict=dtc.predict(X_valid)\n",
    "print(\"Accuracy on Validation set is: \"+str(accuracy_score(y_valid,y_val_predict)))\n",
    "print(\"F1 score of Validation set is: \"+str(f1_score(y_valid,y_val_predict,average='micro')))\n",
    "y_test_predict=dtc.predict(X_test)\n",
    "print(\"Accuracy on Test set is: \"+str(accuracy_score(y_test,y_test_predict)))\n",
    "print(\"F1 score of Test set is: \"+str(f1_score(y_test,y_test_predict,average='micro')))\n",
    "\n",
    "rand_forest=RandomForestClassifier(n_estimators=153,random_state=42,n_jobs=-1,warm_start=True,criterion=\"entropy\")\n",
    "rand_forest.fit(X_train,y_train)\n",
    "y_val_predict=rand_forest.predict(X_valid)\n",
    "print(\"Accuracy on Validation set is: \"+str(accuracy_score(y_valid,y_val_predict)))\n",
    "print(\"F1 score of Validation set is: \"+str(f1_score(y_valid,y_val_predict,average='micro')))\n",
    "y_test_predict=rand_forest.predict(X_test)\n",
    "print(\"Accuracy on Test set is: \"+str(accuracy_score(y_test,y_test_predict)))\n",
    "print(\"F1 score of Test set is: \"+str(f1_score(y_test,y_test_predict,average='micro')))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "421876daddb5e369805e3daf1a0f6acb366b2f3dd62c7bb09c21b42df7ba1d18"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
